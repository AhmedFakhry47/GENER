{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTOarphViFjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c0adc0c-0e12-4aa9-d330-80bf706ea433",
        "cellView": "form"
      },
      "source": [
        "#@title Regulatory Gene Network Inference\n",
        "DATASET = 'Yeastract' #@param[\"Yeastract\",\"DREAM5\"]\n",
        "\n",
        "#@markdown ### Training Parameters\n",
        "Epochs    =  50#@param\n",
        "BatchSize =  64 #@param\n",
        "Classification = 'Connection-Only' #@param ['Connection-Only','Connection_w_Regulation']\n",
        "UseDefault = False #@param {type:\"boolean\"}\n",
        "\n",
        "GetROCcurve  = True #@param {type:\"boolean\"}\n",
        "GetPRcurve   = True #@param {type:\"boolean\"}\n",
        "GetMCC       = True #@param {type:\"boolean\"}\n",
        "SaveModel = True #@param {type:\"boolean\"}\n",
        "SaveDir   =  '/content/trial/'#@param {type:\"string\"}\n",
        "\n",
        "params = {'train_p':{'epochs':Epochs,'batchsize':BatchSize,'n_classes':4 if 'regulation' in Classification.lower() else 2},\n",
        "          'log_p':[GetROCcurve,GetPRcurve,GetMCC,SaveModel,SaveDir],\n",
        "          'dataset':DATASET}\n",
        "\n",
        "if UseDefault:\n",
        "  params = {'train_p':{'epochs':300,'batchsize':64 if 'yeastract' in DATASET.lower() else 8,'n_classes':4 },\n",
        "          'log_p':[True,True,True,True,'/content/default_trained'],\n",
        "          'dataset':DATASET}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Start Training\n",
        "Train = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Train:\n",
        "  start_training(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "5388\n",
            "674\n",
            "674\n",
            "Epoch 1/50\n",
            "84/84 [==============================] - 7s 46ms/step - loss: 0.9603 - Accuracy: 0.5757 - auc_5: 0.6000 - val_loss: 0.7587 - val_Accuracy: 0.6706 - val_auc_5: 0.7177\n",
            "Epoch 2/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.7688 - Accuracy: 0.6360 - auc_5: 0.6840 - val_loss: 0.6337 - val_Accuracy: 0.6884 - val_auc_5: 0.7468\n",
            "Epoch 3/50\n",
            "84/84 [==============================] - 6s 71ms/step - loss: 0.6780 - Accuracy: 0.6784 - auc_5: 0.7283 - val_loss: 0.6540 - val_Accuracy: 0.7092 - val_auc_5: 0.7698\n",
            "Epoch 4/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.6156 - Accuracy: 0.7039 - auc_5: 0.7636 - val_loss: 0.5632 - val_Accuracy: 0.7478 - val_auc_5: 0.7947\n",
            "Epoch 5/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5885 - Accuracy: 0.7147 - auc_5: 0.7781 - val_loss: 0.5763 - val_Accuracy: 0.7255 - val_auc_5: 0.7985\n",
            "Epoch 6/50\n",
            "84/84 [==============================] - 6s 71ms/step - loss: 0.5554 - Accuracy: 0.7308 - auc_5: 0.7977 - val_loss: 0.5453 - val_Accuracy: 0.7181 - val_auc_5: 0.8031\n",
            "Epoch 7/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5558 - Accuracy: 0.7251 - auc_5: 0.7957 - val_loss: 0.5379 - val_Accuracy: 0.7315 - val_auc_5: 0.8128\n",
            "Epoch 8/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5428 - Accuracy: 0.7314 - auc_5: 0.8039 - val_loss: 0.5827 - val_Accuracy: 0.7107 - val_auc_5: 0.8095\n",
            "Epoch 9/50\n",
            "84/84 [==============================] - 4s 45ms/step - loss: 0.5311 - Accuracy: 0.7416 - auc_5: 0.8151 - val_loss: 0.5348 - val_Accuracy: 0.7285 - val_auc_5: 0.8214\n",
            "Epoch 10/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5192 - Accuracy: 0.7502 - auc_5: 0.8245 - val_loss: 0.5446 - val_Accuracy: 0.7389 - val_auc_5: 0.8271\n",
            "Epoch 11/50\n",
            "84/84 [==============================] - 6s 71ms/step - loss: 0.5203 - Accuracy: 0.7515 - auc_5: 0.8235 - val_loss: 0.5259 - val_Accuracy: 0.7404 - val_auc_5: 0.8196\n",
            "Epoch 12/50\n",
            "84/84 [==============================] - 3s 39ms/step - loss: 0.5124 - Accuracy: 0.7547 - auc_5: 0.8302 - val_loss: 0.5280 - val_Accuracy: 0.7329 - val_auc_5: 0.8215\n",
            "Epoch 13/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5127 - Accuracy: 0.7556 - auc_5: 0.8293 - val_loss: 0.5120 - val_Accuracy: 0.7478 - val_auc_5: 0.8276\n",
            "Epoch 14/50\n",
            "84/84 [==============================] - 6s 71ms/step - loss: 0.5047 - Accuracy: 0.7548 - auc_5: 0.8326 - val_loss: 0.5198 - val_Accuracy: 0.7418 - val_auc_5: 0.8282\n",
            "Epoch 15/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5032 - Accuracy: 0.7563 - auc_5: 0.8353 - val_loss: 0.5309 - val_Accuracy: 0.7315 - val_auc_5: 0.8180\n",
            "Epoch 16/50\n",
            "84/84 [==============================] - 3s 39ms/step - loss: 0.5087 - Accuracy: 0.7567 - auc_5: 0.8316 - val_loss: 0.5130 - val_Accuracy: 0.7374 - val_auc_5: 0.8230\n",
            "Epoch 17/50\n",
            "84/84 [==============================] - 6s 73ms/step - loss: 0.4999 - Accuracy: 0.7530 - auc_5: 0.8362 - val_loss: 0.5381 - val_Accuracy: 0.7389 - val_auc_5: 0.8247\n",
            "Epoch 18/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5021 - Accuracy: 0.7526 - auc_5: 0.8347 - val_loss: 0.5310 - val_Accuracy: 0.7389 - val_auc_5: 0.8209\n",
            "Epoch 19/50\n",
            "84/84 [==============================] - 6s 71ms/step - loss: 0.4969 - Accuracy: 0.7615 - auc_5: 0.8393 - val_loss: 0.5094 - val_Accuracy: 0.7507 - val_auc_5: 0.8252\n",
            "Epoch 20/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.4978 - Accuracy: 0.7632 - auc_5: 0.8388 - val_loss: 0.5234 - val_Accuracy: 0.7522 - val_auc_5: 0.8217\n",
            "Epoch 21/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.4948 - Accuracy: 0.7608 - auc_5: 0.8412 - val_loss: 0.5164 - val_Accuracy: 0.7478 - val_auc_5: 0.8335\n",
            "Epoch 22/50\n",
            "84/84 [==============================] - 6s 71ms/step - loss: 0.4928 - Accuracy: 0.7539 - auc_5: 0.8422 - val_loss: 0.5030 - val_Accuracy: 0.7567 - val_auc_5: 0.8352\n",
            "Epoch 23/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.4874 - Accuracy: 0.7634 - auc_5: 0.8460 - val_loss: 0.5319 - val_Accuracy: 0.7433 - val_auc_5: 0.8263\n",
            "Epoch 24/50\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.4863 - Accuracy: 0.7645 - auc_5: 0.8470 - val_loss: 0.5356 - val_Accuracy: 0.7359 - val_auc_5: 0.8297\n",
            "Epoch 25/50\n",
            "84/84 [==============================] - 6s 71ms/step - loss: 0.4944 - Accuracy: 0.7600 - auc_5: 0.8410 - val_loss: 0.5347 - val_Accuracy: 0.7389 - val_auc_5: 0.8318\n",
            "Epoch 26/50\n",
            "84/84 [==============================] - 3s 39ms/step - loss: 0.4823 - Accuracy: 0.7608 - auc_5: 0.8474 - val_loss: 0.5220 - val_Accuracy: 0.7270 - val_auc_5: 0.8245\n",
            "Epoch 27/50\n",
            "83/84 [============================>.] - ETA: 0s - loss: 0.4785 - Accuracy: 0.7654 - auc_5: 0.8504"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fef9bb8a5556>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-103762f221b3>\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mdata_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDATA_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTEST_I\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Connection'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'No-Connection'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GeneA->R->GeneB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GeneB->R->GeneA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msavedir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msavedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mFindrML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFindrML_TRAINER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDATA_Y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRAIN_I\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAL_I\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTEST_I\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;34m[\u001b[0m\u001b[0mGetROCcurve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGetPRcurve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGetMCC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSaveModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSaveDir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-da07460e5090>\u001b[0m in \u001b[0;36mFindrML_TRAINER\u001b[0;34m(*params, **DATA)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVAL_I\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST_I\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mFindrML\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_G\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL_G\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mFindrML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                         )\n\u001b[0;32m-> 1791\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1792\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m                         ):\n\u001b[1;32m   2199\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2201\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   3998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4000\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4001\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4002\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    862\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns-Ern3qzMk8"
      },
      "source": [
        "# Run First"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65AjTwzrzLx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1fdab7-0ea5-49c0-d8e1-af3f292909e5"
      },
      "source": [
        "!git clone https://github.com/AhmedFakhry47/Regulatory-Gene-Network-Inferance-from-gene-exepression-data\n",
        "\n",
        "from sklearn.metrics import roc_curve,roc_auc_score,auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import Callback\n",
        "from tensorflow import keras\n",
        "from itertools import cycle\n",
        "from scipy import interp\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import pickle\n",
        "import json\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Regulatory-Gene-Network-Inferance-from-gene-exepression-data'...\n",
            "remote: Enumerating objects: 782, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 782 (delta 28), reused 78 (delta 28), pack-reused 704\u001b[K\n",
            "Receiving objects: 100% (782/782), 262.63 MiB | 20.98 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oxunROvMMxv"
      },
      "source": [
        "def start_training(params):\n",
        "  '''\n",
        "  This function takes:\n",
        "  1- Training parameters such as batch size, # of epochs, etc.\n",
        "  2- Type of metrics to evaluate model performance with\n",
        "  3- The chosen dataset to train model over\n",
        "\n",
        "  It initiates three pure functions, one for downloading and balancing the data,\n",
        "  the second one calls the model and starts training, while the third one saves the model\n",
        "  and evaluates other statistical metrics.\n",
        "  '''\n",
        "  #Decode parameters\n",
        "  if params:\n",
        "    dataset = params['dataset']\n",
        "    logpars = params['log_p'][:4]\n",
        "    savedir = params['log_p'][-1]\n",
        "\n",
        "    epochs,batchsize,n_classes  = params['train_p']['epochs'],params['train_p']['batchsize'],params['train_p']['n_classes']\n",
        "\n",
        "  print(n_classes)\n",
        "  if not os.path.isdir(savedir):\n",
        "    os.mkdir(savedir)\n",
        "\n",
        "  #First, load and balance dataset to make it ready for training\n",
        "  DATA_X,DATA_Y,TRAIN_I,VAL_I,TEST_I = load_data(dataset = dataset)\n",
        "  data_stats(DATA_X,DATA_Y,TEST_I,names=['Connection','No-Connection','GeneA->R->GeneB','GeneB->R->GeneA'],savedir=savedir)\n",
        "\n",
        "  FindrML = FindrML_TRAINER(epochs,batchsize,n_classes,DATA={'data':[DATA_X,DATA_Y],'index':[TRAIN_I,VAL_I,TEST_I]})\n",
        "\n",
        "  [GetROCcurve,GetPRcurve,GetMCC,SaveModel,SaveDir]\n",
        "\n",
        "  print('\\n- - - - - - - - - - - - - - - - - - - - - -\\n')\n",
        "  print('Metrics Scores:')\n",
        "  print('- - - - - - - - - - - - - - - - - - - - - -\\n')\n",
        "  if logpars[0]: calc_AUC(True,savedir,'FindrML_ROC',preds=FindrML.predict(DATA_X[TEST_I]),labels=DATA_Y[TEST_I][:,:n_classes],n_classes=n_classes)\n",
        "  print('-----\\n')\n",
        "  if logpars[1]: calc_PR(preds=FindrML.predict(DATA_X[TEST_I]),labels=DATA_Y[TEST_I][:,:n_classes],n_classes=n_classes,savedir=savedir)\n",
        "  print('-----\\n')\n",
        "  if logpars[2]: calc_MCC(preds=FindrML.predict(DATA_X[TEST_I]),labels=DATA_Y[TEST_I][:,:n_classes],n_classes=n_classes)\n",
        "  print('-----\\n')\n",
        "  if logpars[3]: save_model(kerasmodel=FindrML,savedir=savedir,name='FindrML')\n",
        "  print('- - - - - - - - - - - - - - - - - - - - - -\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ux6Zx_Q697n"
      },
      "source": [
        "def FindrML_TRAINER(*params,**DATA):\n",
        "  if DATA:\n",
        "    DATA_X,DATA_Y = DATA['DATA']['data']\n",
        "    TRAIN_I,VAL_I,TEST_I = DATA['DATA']['index']\n",
        "  print(len(TRAIN_I))\n",
        "  print(len(VAL_I))\n",
        "  print(len(TEST_I))\n",
        "\n",
        "  if params:\n",
        "    epochs,batchsize,n_classes = params[0],params[1],params[2]\n",
        "  else:\n",
        "    epochs,batchsize,n_classes = 300,8,4\n",
        "\n",
        "  TRAIN_G = MULTI_G(DATA_X[TRAIN_I],DATA_Y[TRAIN_I][:,:n_classes],batch_size=batchsize,n_classes=n_classes)\n",
        "  VAL_G   = MULTI_G(DATA_X[VAL_I]  ,DATA_Y[VAL_I][:,:n_classes]  ,batch_size=1 ,n_classes=n_classes)\n",
        "  TEST_G  = MULTI_G(DATA_X[TEST_I] ,DATA_Y[TEST_I][:,:n_classes] ,batch_size=1 ,n_classes=n_classes)\n",
        "\n",
        "  FindrML  = Shallow_M(n_classes=n_classes,act='softmax')\n",
        "\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=2500,\n",
        "    decay_rate=0.8)\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "  FindrML.compile(optimizer=optimizer,loss='CategoricalCrossentropy' ,\n",
        "                  metrics=['Accuracy',tf.keras.metrics.AUC(multi_label=True)])\n",
        "\n",
        "  earlystop = tf.keras.callbacks.EarlyStopping('val_loss',patience=100,restore_best_weights=True)\n",
        "  evaluator = Evaluation(VAL_G, DATA_Y[VAL_I], TEST_G, DATA_Y[TEST_I],multi=True)\n",
        "\n",
        "  FindrML.fit(TRAIN_G,epochs=epochs,validation_data=VAL_G,callbacks=[earlystop])\n",
        "\n",
        "  return FindrML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK0WD_oyZwfI"
      },
      "source": [
        "def get_data(dataset):\n",
        "  scripts = []\n",
        "  for dirs,_,fils in os.walk('/content/'):\n",
        "    for file in fils:\n",
        "      if '.sh' in file:\n",
        "        scripts.append(os.path.join(dirs,file))\n",
        "\n",
        "  if 'yeastract' in dataset.lower():\n",
        "    script = [i for i in scripts if 'yeast' in i][0]\n",
        "  elif 'dream'   in dataset.lower():\n",
        "    script = [i for i in scripts if 'dream' in i][0]\n",
        "\n",
        "  subprocess.call(['chmod','+777',script])\n",
        "  subprocess.call(['./'+script[9:]])\n",
        "\n",
        "\n",
        "def preprocess_yeastract(dirc):\n",
        "  def open_file(direc):\n",
        "    file = open(direc,'r+')\n",
        "\n",
        "    for row in file.readlines():\n",
        "      row    = row.split('\\n')[0]\n",
        "      elems  = row.split(',')\n",
        "      yield elems\n",
        "\n",
        "  class numpy_encoder(json.JSONEncoder):\n",
        "    def default(self,obj):\n",
        "      if isinstance(obj,np.ndarray):\n",
        "        return obj.tolist()\n",
        "      return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "  def ret(row,columns):\n",
        "    keys = [row +'-'+c if i%2 ==0 else c+'-'+row for i,c in enumerate(columns)]\n",
        "    return keys\n",
        "\n",
        "  yeastract = {}\n",
        "  files  = {}\n",
        "\n",
        "  for dirs,keys,fils in os.walk(dirc):\n",
        "    for fil in fils:\n",
        "      if 'expression' in fil.lower():\n",
        "        files['expression'] = os.path.join(dirs,fil)\n",
        "\n",
        "      elif 'regulation' in fil.lower():\n",
        "        files['regulation'] = os.path.join(dirs,fil)\n",
        "\n",
        "  #To get gene expressions\n",
        "  genes_file  = open_file(files['expression'])\n",
        "\n",
        "  genes_N     = [gene for gene in next(genes_file)[1:]]\n",
        "  expressions = []\n",
        "  genes       = {}\n",
        "\n",
        "\n",
        "  for row in genes_file:\n",
        "    expressions.append(row[1:])\n",
        "\n",
        "  expressions = np.array(expressions,dtype=np.float64).T\n",
        "\n",
        "  for j,gene in enumerate(genes_N):\n",
        "    genes[gene] = expressions[j]\n",
        "\n",
        "  del expressions\n",
        "  #To store labels\n",
        "  groundTs = open_file(files['regulation'])\n",
        "  columns  = next(groundTs)[1:]\n",
        "  rows     = []\n",
        "\n",
        "  matrix   = []\n",
        "  for p,groundT in enumerate(groundTs):\n",
        "    rows.append(groundT[0])\n",
        "    matrix.append(list(map(int,groundT[1:])))\n",
        "\n",
        "  matrix = np.reshape(np.array(matrix),(len(rows),len(columns)))\n",
        "  for i,row in enumerate(rows):\n",
        "    keys = ret(row,columns)\n",
        "    for j,key in enumerate(keys):\n",
        "      if key not in yeastract:\n",
        "        yeastract[key] = {}\n",
        "        try:\n",
        "          yeastract[key]['Expression_A'] = genes[key.split('-')[0]]\n",
        "          yeastract[key]['Expression_B'] = genes[key.split('-')[1]]\n",
        "        except:\n",
        "          del yeastract[key]\n",
        "          continue\n",
        "        yeastract[key]['Labelx']= matrix[i,j]\n",
        "        yeastract[key]['Labely']= 1 - matrix[i,j]\n",
        "        yeastract[key]['P']     = 1 if (matrix[i,j] == 1 and j%2 ==0) else 0\n",
        "        yeastract[key]['N']     = 1 if (matrix[i,j] == 1 and j%2 !=0) else 0\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "  return yeastract\n",
        "\n",
        "def preprocess_dream(dirc):\n",
        "  DATA = None\n",
        "  for dirs,keys,fils in os.walk(dirc):\n",
        "    for fil in fils:\n",
        "      if 'preprocessed.json' in fil.lower():\n",
        "        JFILE = open(os.path.join(dirs,fil),'r')\n",
        "        DATA  = json.load(JFILE)\n",
        "\n",
        "  return DATA\n",
        "\n",
        "\n",
        "def extract(data,sampler=50000,specify=False):\n",
        "  E_DATA = {'geneEx':[],'label':[]}\n",
        "\n",
        "  if specify:\n",
        "    selector = list(data.keys())[:sampler]\n",
        "  else:\n",
        "    selector = list(data.keys())\n",
        "\n",
        "  for key in selector:\n",
        "    E_DATA['geneEx'].append([data[key]['Expression_A'],data[key]['Expression_B']])\n",
        "    label = []\n",
        "    E_DATA['label'].append([data[key]['Labelx'],data[key]['Labely'],data[key]['P'],data[key]['N']])\n",
        "\n",
        "  E_DATA['geneEx'] = np.array(E_DATA['geneEx'], dtype=np.float64)\n",
        "  E_DATA['label']  = np.array(E_DATA['label'])\n",
        "\n",
        "  return E_DATA\n",
        "\n",
        "def balance(labely,tobalance_class = 0):\n",
        "  '''\n",
        "  Takes:\n",
        "  1-Labels for two or more multi-label classification problem\n",
        "  2-Which class to balance over\n",
        "  Returns: Indices for balanced train-val-test splits\n",
        "  '''\n",
        "\n",
        "  one_index = [i for i in range(len(labely)) if labely[i][tobalance_class] == 1]\n",
        "  zer_index = [i for i in range(len(labely)) if labely[i][tobalance_class] == 0]\n",
        "\n",
        "  np.random.shuffle(one_index)\n",
        "  np.random.shuffle(zer_index)\n",
        "\n",
        "  R_index = [i for j in [one_index , zer_index[:len(one_index)]] for i in j]\n",
        "\n",
        "  np.random.shuffle(R_index)\n",
        "\n",
        "  train_index = R_index[:int(0.8*len(R_index))]\n",
        "  val_index   = R_index[int(0.8*len(R_index)):int(0.9*len(R_index))]\n",
        "  test_index  = R_index[int(0.9*len(R_index)):]\n",
        "\n",
        "  return train_index,val_index,test_index\n",
        "\n",
        "def data_stats(input_X,label_Y,indices,names=None,savedir=None):\n",
        "  t_d = input_X[indices]\n",
        "  t_dy= label_Y[indices]\n",
        "\n",
        "  if names: classes = names\n",
        "  else: classes = ['class-'+str(i) for i in range(t_dy.shape[1])]\n",
        "\n",
        "  values  = []\n",
        "  for i in range(t_dy.shape[1]):\n",
        "    values.append(len(np.where(t_dy[:,i]==1)[0]))\n",
        "\n",
        "  if not os.path.isdir(savedir):\n",
        "    os.mkdir(savedir)\n",
        "\n",
        "  plt.figure(figsize=(25, 10))\n",
        "  plt.subplot(131)\n",
        "  plt.bar(names, values)\n",
        "\n",
        "  plt.title('Data Statistics')\n",
        "  plt.savefig(os.path.join(savedir,'Data_Statistics.png'))\n",
        "  plt.close()\n",
        "\n",
        "def load_data(dataset):\n",
        "  DATA = {}\n",
        "\n",
        "  #Run scripts to load data from cloned repo\n",
        "  get_data(dataset)\n",
        "  #Preprocess Data\n",
        "  if 'yeastract' in dataset.lower():\n",
        "    DATA = preprocess_yeastract('/content')\n",
        "  else:\n",
        "    DATA = preprocess_dream('/content')\n",
        "\n",
        "  #Extract inputX and labelY from the json file\n",
        "  DATA   = extract(DATA,specify=True)\n",
        "\n",
        "  #Balance data labels\n",
        "  TRAIN_I,VAL_I,TEST_I = balance(DATA['label'],tobalance_class=0)\n",
        "\n",
        "  return [DATA['geneEx'],DATA['label'],TRAIN_I,VAL_I,TEST_I]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifEd7oahTjR1"
      },
      "source": [
        "def save_roc(*scores,name='ROC_CURVE.png',ROCdir='/content',n_classes=3):\n",
        "  if scores:\n",
        "    fpr,tpr,roc_auc = scores[0],scores[1],scores[2]\n",
        "  else:\n",
        "    print('Please insert scores to plot the roc curve')\n",
        "    return\n",
        "\n",
        "  if n_classes >1 and not isinstance(fpr,dict) :\n",
        "    print('please enter scores for all classes to continue ..')\n",
        "    return\n",
        "\n",
        "  if not os.path.isdir(ROCdir):\n",
        "    os.mkdir(ROCdir)\n",
        "\n",
        "    # Plot all ROC curves\n",
        "  plt.figure(figsize=[8, 8])\n",
        "  lw = 2\n",
        "  plt.plot(fpr[\"micro\"], tpr[\"micro\"],label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]),\n",
        "          color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "  colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "  for i, color in zip(range(n_classes), colors):\n",
        "      plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "              label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "\n",
        "  plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Model Performance')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.savefig(os.path.join(ROCdir,name+'.png'))\n",
        "  plt.close()\n",
        "\n",
        "def calc_AUC(*saveargs,preds,labels,n_classes=4):\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "  for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(labels[:, i], preds[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "  fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(labels.ravel(), preds.ravel())\n",
        "  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "  print('Micro-Average = {}\\n'.format(roc_auc[\"micro\"]))\n",
        "  if saveargs:\n",
        "    print('Saving ROC curve ...\\n')\n",
        "    save,path,name = saveargs[0],saveargs[1],saveargs[2]\n",
        "    if save:\n",
        "      save_roc(fpr,tpr,roc_auc,name=name,ROCdir=path,n_classes=n_classes)\n",
        "      print('ROC curve is saved ..\\n')\n",
        "\n",
        "def save_model(kerasmodel,savedir,name):\n",
        "\n",
        "  if '.' in name:\n",
        "    name = ''.join(name.split('.')[0])\n",
        "\n",
        "  if not os.path.isdir(savedir):\n",
        "    os.mkdir(savedir)\n",
        "\n",
        "  kerasmodel.save(os.path.join(savedir,name),save_format='tf')\n",
        "  print('Model is saved ..\\n')\n",
        "\n",
        "def calc_MCC(preds,labels,n_classes):\n",
        "  print('Matthews Correlation Coefficients:\\n')\n",
        "  for i in range(n_classes):\n",
        "    print('Class {}: {}\\n'.format(i,matthews_corrcoef(labels[:, i], preds[:, i].round())))\n",
        "  print('\\n')\n",
        "\n",
        "def calc_PR(preds,labels,n_classes,savedir):\n",
        "  # For each class\n",
        "  precision = dict()\n",
        "  recall = dict()\n",
        "  average_precision = dict()\n",
        "\n",
        "  for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(labels[:, i],preds[:, i])\n",
        "\n",
        "  # A \"micro-average\": quantifying score on all classes jointly\n",
        "  precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(labels.ravel(),preds.ravel())\n",
        "\n",
        "  average_precision[\"micro\"] = average_precision_score(labels, preds,average=\"micro\")\n",
        "\n",
        "  plt.figure(figsize=[10, 10])\n",
        "  lw = 2\n",
        "  plt.step(recall['micro'], precision['micro'], where='post')\n",
        "\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.title('Average precision score, micro-averaged over all classes: AP={0:0.2f}'.format(average_precision[\"micro\"]))\n",
        "  plt.savefig(os.path.join(savedir,'PR'+'.png'))\n",
        "  plt.close()\n",
        "\n",
        "  print('Precision recall curve is saved ..\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl8W3yg-ZZQf"
      },
      "source": [
        "\n",
        "class Evaluation(keras.callbacks.Callback):\n",
        "  def __init__(self, val_data_gen, val_labels, test_data_gen, test_labels,multi=True):\n",
        "    super(keras.callbacks.Callback, self).__init__()\n",
        "    self.test_data   = test_data_gen\n",
        "    self.val_labels  = val_labels\n",
        "    self.val_data    = val_data_gen\n",
        "    self.test_labels = test_labels\n",
        "\n",
        "    if multi == True:\n",
        "      self.param = 'ovr'\n",
        "    else:\n",
        "      self.param = 'raise'\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    y_preds = self.model.predict_generator(self.val_data)\n",
        "    print(' | val_auc:', roc_auc_score(self.val_labels[:len(y_preds)], y_preds,multi_class=self.param))\n",
        "\n",
        "    y_preds = self.model.predict_generator(self.test_data)\n",
        "    print(' | test_auc:', roc_auc_score(self.test_labels[:len(y_preds)], y_preds,multi_class=self.param))\n",
        "\n",
        "class MULTI_G(tf.keras.utils.Sequence):\n",
        "  def __init__(self,genes,labels,batch_size,n_classes=1,shuffle=True):\n",
        "    self.batch_size = batch_size\n",
        "    self.labels     = labels\n",
        "    self.genes      = genes\n",
        "    self.n_classes  = n_classes\n",
        "    self.shuffle    = shuffle\n",
        "    self.dim = self.genes.shape[1:]\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.genes) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "    X, y = self.__data_generation(indexes)\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(len(self.genes))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    X = np.empty((self.batch_size, *self.dim))\n",
        "    y = np.empty((self.batch_size,self.n_classes))\n",
        "\n",
        "    # Generate data\n",
        "    for i, ID in enumerate(list_IDs_temp):\n",
        "      #Melspec\n",
        "      X[i,]  = self.genes[ID]\n",
        "\n",
        "      # Store class\n",
        "      y[i,]  = self.labels[ID]\n",
        "\n",
        "    return X, y\n",
        "\n",
        "class Shallow_M (tf.keras.Model):\n",
        "  def __init__(self,n_classes=1,act='sig',training=True):\n",
        "    super(Shallow_M,self).__init__()\n",
        "    self.DenseA   = tf.keras.layers.Dense(256,activation=tf.nn.relu)\n",
        "    self.BatchN_A = tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "    self.DropO_A  = tf.keras.layers.Dropout(rate=0.5)\n",
        "\n",
        "    self.DenseB   = tf.keras.layers.Dense(256,activation=tf.nn.relu)\n",
        "    self.BatchN_B = tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "    self.DropO_B  = tf.keras.layers.Dropout(rate=0.5)\n",
        "    self.FlattenX = tf.keras.layers.Flatten()\n",
        "\n",
        "    self.CnnD     = tf.keras.layers.Conv2D(filters=16,kernel_size=2,)\n",
        "    self.BatchN_D = tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "    self.DropO_D  = tf.keras.layers.Dropout(rate=0.5)\n",
        "\n",
        "    self.CnnE     = tf.keras.layers.Conv2D(filters=8,kernel_size=1,)\n",
        "    self.BatchN_E = tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "    self.DropO_E  = tf.keras.layers.Dropout(rate=0.5)\n",
        "\n",
        "    self.Flatten  = tf.keras.layers.Flatten()\n",
        "    self.DenseD   = tf.keras.layers.Dense(32,activation=tf.nn.relu)\n",
        "    self.BatchN_DD= tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "    self.DropO_DD = tf.keras.layers.Dropout(rate=0.5)\n",
        "\n",
        "    if (act == 'sig'):\n",
        "      self.Predict  = tf.keras.layers.Dense(n_classes,activation=tf.nn.sigmoid)\n",
        "    else:\n",
        "      self.Predict  = tf.keras.layers.Dense(n_classes,activation=tf.nn.softmax)\n",
        "\n",
        "    self.training = training\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = tf.math.reduce_prod(inputs,axis=1)\n",
        "\n",
        "    x = self.DenseA(x)\n",
        "    x = self.BatchN_A(x,)\n",
        "    x = self.DropO_A(x,training=self.training)\n",
        "\n",
        "    x = self.DenseB(x)\n",
        "    x = self.BatchN_B(x,)\n",
        "    x = self.DropO_B(x,training=self.training)\n",
        "    x = self.FlattenX(x)\n",
        "\n",
        "    d = self.CnnD(inputs[:,:,:,np.newaxis])\n",
        "    d = self.BatchN_D(d)\n",
        "    d = self.DropO_D(d)\n",
        "\n",
        "    d = self.CnnE(d)\n",
        "    d = self.BatchN_E(d)\n",
        "    d = self.DropO_E(d)\n",
        "\n",
        "    out = self.Flatten(d)\n",
        "    out = self.DenseD(out)\n",
        "    out = self.BatchN_DD(out)\n",
        "    out = self.DropO_DD(out)\n",
        "\n",
        "    out = tf.keras.layers.concatenate([x,out])\n",
        "\n",
        "    return self.Predict(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2oKnfb3yple"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}